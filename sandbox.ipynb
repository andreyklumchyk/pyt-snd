{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K7i_BtMkYGi"
      },
      "source": [
        "# AI test task"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies"
      ],
      "metadata": {
        "id": "6AWfcjavxYVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qJnno20jJ_K",
        "outputId": "565b1378-65f8-4fbd-80ca-38456e5cd05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers einops\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from transformers import TextIteratorStreamer, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "class ModelLoader:\n",
        "    def __init__(self):\n",
        "        model_name = \"vikhyatk/moondream2\"\n",
        "        revision = \"2024-08-26\"\n",
        "        #model_id = \"vikhyatk/moondream2\"\n",
        "        #revision = \"2024-05-08\"\n",
        "        self._model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, trust_remote_code=True, revision=revision\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        self._tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name, revision=revision\n",
        "        )\n",
        "        self._model.eval()\n",
        "\n",
        "    def get_image_by_url(self, url):\n",
        "        response = requests.get(url)\n",
        "        return Image.open(BytesIO(response.content))\n",
        "\n",
        "    def image_ask(self, url, question):\n",
        "        enc_image = self._model.encode_image(self.get_image_by_url(url))\n",
        "        return self._model.answer_question(\n",
        "            enc_image, question,\n",
        "            self._tokenizer\n",
        "        )\n",
        "\n",
        "\n",
        "model_loader = ModelLoader()"
      ],
      "metadata": {
        "id": "O8hkhRL72fHu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interface implementation"
      ],
      "metadata": {
        "id": "Xx9njQqAx7_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "TITLE = \"\"\"\n",
        "    <div style=\"text-align: center; max-width: 650px; margin: 0 auto;\">\n",
        "        <div\n",
        "        style=\"\n",
        "            display: inline-flex;\n",
        "            align-items: center;\n",
        "            gap: 0.8rem;\n",
        "            font-size: 1.75rem;\n",
        "        \"\n",
        "        >\n",
        "        <h1 style=\"font-weight: 900; margin-bottom: 7px;\">\n",
        "            CLIP Interrogator\n",
        "        </h1>\n",
        "        </div>\n",
        "    </div>\n",
        "\"\"\"\n",
        "\n",
        "IMAGES = [\n",
        "    \"https://raw.githubusercontent.com/andreyklumchyk/pyt-snd/main/img/cat.jpg\",\n",
        "    \"https://raw.githubusercontent.com/andreyklumchyk/pyt-snd/main/img/dog.jpg\",\n",
        "    \"https://raw.githubusercontent.com/andreyklumchyk/pyt-snd/main/img/turtle.jpg\",\n",
        "    \"https://raw.githubusercontent.com/andreyklumchyk/pyt-snd/main/img/human.jpg\",\n",
        "    \"https://raw.githubusercontent.com/andreyklumchyk/pyt-snd/main/img/woman.jpg\"\n",
        "]\n",
        "\n",
        "\n",
        "CURRENT_IMAGE_URL = None\n",
        "\n",
        "\n",
        "def select_image(selection: gr.SelectData):\n",
        "    global CURRENT_IMAGE_URL\n",
        "    CURRENT_IMAGE_URL = selection.value['image']['path']\n",
        "    gr.Info(\"Image selected\")\n",
        "\n",
        "\n",
        "def selected_image_describe():\n",
        "    if not CURRENT_IMAGE_URL:\n",
        "        gr.Warning(\"No image selected!\")\n",
        "        return None\n",
        "\n",
        "    return model_loader.image_ask(CURRENT_IMAGE_URL, \"Describe this image.\")\n",
        "\n",
        "\n",
        "def selected_image_test():\n",
        "    if not CURRENT_IMAGE_URL:\n",
        "        gr.Warning(\"No image selected!\")\n",
        "        return None\n",
        "\n",
        "    questions = [\n",
        "        \"Is it a photo? Answer only \\\"Yes\\\" or \\\"No\\\".\",\n",
        "        \"Is it a human? Answer only \\\"Yes\\\" or \\\"No\\\".\",\n",
        "        \"Is it alone? Answer only \\\"Yes\\\" or \\\"No\\\".\",\n",
        "        \"Is it a woman? Answer only \\\"Yes\\\" or \\\"No\\\".\",\n",
        "        \"Is it happy? Answer only \\\"Yes\\\" or \\\"No\\\".\"\n",
        "    ]\n",
        "    result = []\n",
        "    for question in questions:\n",
        "        out = model_loader.image_ask(CURRENT_IMAGE_URL, question)\n",
        "        result.append(out == 'Yes')\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def analyze_tab():\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery(\n",
        "                label=\"Pickup any image\",\n",
        "                preview=True,\n",
        "                value=IMAGES,\n",
        "                show_label=False,\n",
        "                elem_id=\"gallery\",\n",
        "                columns=[2], rows=[2],\n",
        "                object_fit=\"contain\",\n",
        "                height=800,\n",
        "                allow_preview=False,\n",
        "                selected_index=None,\n",
        "            )\n",
        "\n",
        "            gallery.select(select_image, inputs=None, outputs=None)\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Description\", elem_id=\"output-txt\")\n",
        "            describe_button = gr.Button(\"Describe\")\n",
        "\n",
        "            is_photo = gr.Checkbox(label=\"Is a photo?\")\n",
        "            is_human = gr.Checkbox(label=\"Is a human?\")\n",
        "            is_alone = gr.Checkbox(label=\"Alone?\")\n",
        "            is_woman = gr.Checkbox(label=\"Is it a woman?\")\n",
        "            is_happy = gr.Checkbox(label=\"Is it happy?\")\n",
        "            test_button = gr.Button(\"Test\")\n",
        "\n",
        "    describe_button.click(selected_image_describe, inputs=[], outputs=[output_text])\n",
        "    test_button.click(selected_image_test, inputs=[], outputs=[is_photo, is_human, is_alone, is_woman, is_happy])\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Column(elem_id=\"col-container\"):\n",
        "        gr.HTML(TITLE)\n",
        "\n",
        "        with gr.Tab(\"Analyze\"):\n",
        "            analyze_tab()\n",
        "\n",
        "\n",
        "demo.launch(show_error=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "1FDzDlgVx7YY",
        "outputId": "35839124-8d49-4511-a980-d873e9ec1883"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dc46273161dcd629a2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dc46273161dcd629a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}